{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3:\n",
    "Multiple Mixture components using labeled data: You will relax the assumption made in the\n",
    "first 2 experiments. You will consider that a single news article can belong to several subtopics\n",
    "and experiment with a Naive Bayes classifier using multiple mixture components on the labeled\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bahia cocoa review shower continu throughout w...</td>\n",
       "      <td>['cocoa']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>comput termin system lt cpml complet sale comp...</td>\n",
       "      <td>['acq']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>n z trade bank deposit growth rise slightli ne...</td>\n",
       "      <td>['money-supply']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>nation amus up viacom lt via bid viacom intern...</td>\n",
       "      <td>['acq']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>roger lt rog see st qtr net significantli roge...</td>\n",
       "      <td>['earn']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7764</td>\n",
       "      <td>7764</td>\n",
       "      <td>u k money market shortag forecast revis bank e...</td>\n",
       "      <td>['interest', 'money-fx']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7765</td>\n",
       "      <td>7765</td>\n",
       "      <td>knight ridder inc lt krn set quarterli qtli di...</td>\n",
       "      <td>['earn']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7766</td>\n",
       "      <td>7766</td>\n",
       "      <td>technitrol inc lt tnl set quarterli qtli div c...</td>\n",
       "      <td>['earn']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7767</td>\n",
       "      <td>7767</td>\n",
       "      <td>nationwid cellular servic inc lt ncel th qtr s...</td>\n",
       "      <td>['earn']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7768</td>\n",
       "      <td>7768</td>\n",
       "      <td>lt h automot technolog corp year net shr ct vs...</td>\n",
       "      <td>['earn']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7769 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                                  X  \\\n",
       "0              0  bahia cocoa review shower continu throughout w...   \n",
       "1              1  comput termin system lt cpml complet sale comp...   \n",
       "2              2  n z trade bank deposit growth rise slightli ne...   \n",
       "3              3  nation amus up viacom lt via bid viacom intern...   \n",
       "4              4  roger lt rog see st qtr net significantli roge...   \n",
       "...          ...                                                ...   \n",
       "7764        7764  u k money market shortag forecast revis bank e...   \n",
       "7765        7765  knight ridder inc lt krn set quarterli qtli di...   \n",
       "7766        7766  technitrol inc lt tnl set quarterli qtli div c...   \n",
       "7767        7767  nationwid cellular servic inc lt ncel th qtr s...   \n",
       "7768        7768  lt h automot technolog corp year net shr ct vs...   \n",
       "\n",
       "                             Y  \n",
       "0                    ['cocoa']  \n",
       "1                      ['acq']  \n",
       "2             ['money-supply']  \n",
       "3                      ['acq']  \n",
       "4                     ['earn']  \n",
       "...                        ...  \n",
       "7764  ['interest', 'money-fx']  \n",
       "7765                  ['earn']  \n",
       "7766                  ['earn']  \n",
       "7767                  ['earn']  \n",
       "7768                  ['earn']  \n",
       "\n",
       "[7769 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_cleaned_stemed_reuters.csv', delimiter = ',')\n",
    "test = pd.read_csv('../data/test_cleaned_stemed_reuters.csv', delimiter = ',')\n",
    "train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['interest', 'money-fx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Y'] = train.Y.apply(lambda x: re.sub('\\s+', '', x))\n",
    "train['Y'] = train.Y.apply(lambda x: re.sub('\\'', '', x))\n",
    "train['Y'] = train.Y.apply(lambda x: x[1:-1].split(','))\n",
    "\n",
    "train[\"Y\"][7764]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Y'] = test.Y.apply(lambda x: re.sub('\\s+', '', x))\n",
    "test['Y'] = test.Y.apply(lambda x: re.sub('\\'', '', x))\n",
    "test['Y'] = test.Y.apply(lambda x: x[1:-1].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7769,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.array(train[\"X\"])\n",
    "train_Y = np.array(train[\"Y\"])\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asian export fear damag u japan rift mount trade friction u japan rais fear among mani asia export nation row could inflict far reach econom damag businessmen offici said told reuter correspond asian capit u move japan might boost protectionist sentiment u lead curb american import product export said conflict would hurt long run short term tokyo loss might gain u said impos mln dlr tariff import japanes electron good april retali japan alleg failur stick pact sell semiconductor world market cost unoffici japanes estim put impact tariff billion dlr spokesmen major electron firm said would virtual halt export product hit new tax abl busi said spokesman lead japanes electron firm matsushita electr industri co ltd lt mc tariff remain place length time beyond month mean complet eros export good subject tariff u said tom murtha stock analyst tokyo offic broker lt jame capel co taiwan businessmen offici also worri awar serious u threat japan serv warn us said senior taiwanes trade offici ask name taiwan trade trade surplu billion dlr last year pct u surplu help swell taiwan foreign exchang reserv billion dlr among world largest must quickli open market remov trade barrier cut import tariff allow import u product want defus problem possibl u retali said paul sheen chairman textil export lt taiwan safe group senior offici south korea trade promot associ said trade disput u japan might also lead pressur south korea whose chief export similar japan last year south korea trade surplu billion dlr u billion dlr malaysia trade offic businessmen said tough curb japan might allow hard hit produc semiconductor third countri expand sale u hong kong newspap alleg japan sell cost semiconductor electron manufactur share view businessmen said short term commerci advantag would outweigh u pressur block import short term view said lawrenc mill director gener feder hong kong industri whole purpos prevent import one day extend sourc much seriou hong kong disadvantag action restrain trade said u last year hong kong biggest export market account pct domest produc export australian govern await outcom trade talk u japan interest concern industri minist john button said canberra last friday kind deterior trade relat two countri major trade partner seriou matter button said said australia concern centr coal beef australia two largest export japan also signific u export countri meanwhil u japanes diplomat manoeuvr solv trade stand continu japan rule liber democrat parti yesterday outlin packag econom measur boost japanes economi measur propos includ larg supplementari budget record public work spend first half financi year also call step spend emerg measur stimul economi despit prime minist yasuhiro nakason avow fiscal reform program deputi u trade repres michael smith makoto kuroda japan deputi minist intern trade industri miti due meet washington week effort end disput',\n",
       "       'china daili say vermin eat pct grain stock survey provinc seven citi show vermin consum seven pct china grain stock china daili said also said year mln tonn pct china fruit output left rot mln tonn pct veget paper blame wast inadequ storag bad preserv method said govern launch nation programm reduc wast call improv technolog storag preserv greater product addit paper gave detail'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = np.array(test[\"X\"])\n",
    "test_Y = np.array(test[\"Y\"])\n",
    "test_X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7769, 18034)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "train_data_vectors = vectorizer.fit_transform(train_X)\n",
    "train_data_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3019, 18034)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_vectors = vectorizer.transform(test_X)\n",
    "test_data_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_classifier = MultinomialNB(alpha=0.01)\n",
    "bayes_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "new_y = mlb.fit_transform(train_Y)\n",
    "new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7769, 90)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for n in new_y:\n",
    "    if sum(n) > 1:\n",
    "        print(n)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None,\n",
       "                                              fit_prior=True),\n",
       "                      n_jobs=-1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bayes_classifier.fit(train_data_vectors,new_y)\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "multi_target = MultiOutputClassifier(bayes_classifier, n_jobs=-1)\n",
    "multi_target.fit(train_data_vectors,new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = multi_target.predict(test_data_vectors)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_test = mlb.transform(test_Y)\n",
    "new_y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6840013249420338"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(new_y_test, test_predict)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88       719\n",
      "           1       1.00      0.35      0.52        23\n",
      "           2       0.89      0.57      0.70        14\n",
      "           3       0.85      0.37      0.51        30\n",
      "           4       0.50      0.11      0.18        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.93      0.78      0.85        18\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.93      0.89      0.91        28\n",
      "          10       0.60      0.50      0.55        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.52      0.71      0.60        56\n",
      "          13       0.88      0.35      0.50        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.55      0.21      0.31        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.87      0.86      0.86       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.48      0.73      0.58        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.93      0.93      0.93      1087\n",
      "          22       1.00      0.20      0.33        10\n",
      "          23       1.00      0.47      0.64        17\n",
      "          24       0.84      0.77      0.81        35\n",
      "          25       0.88      0.50      0.64        30\n",
      "          26       0.77      0.87      0.82       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.67      0.40      0.50         5\n",
      "          30       1.00      0.33      0.50         6\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.74      0.76      0.75       131\n",
      "          35       1.00      0.17      0.29        12\n",
      "          36       0.75      0.21      0.33        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       1.00      0.43      0.60        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.58      0.29      0.39        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       1.00      0.16      0.27        19\n",
      "          46       0.67      0.88      0.76       179\n",
      "          47       0.87      0.59      0.70        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.47      0.23      0.31        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       1.00      0.17      0.29         6\n",
      "          54       0.68      0.53      0.60        47\n",
      "          55       1.00      0.64      0.78        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       1.00      0.40      0.57        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       1.00      0.08      0.15        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       1.00      0.44      0.62         9\n",
      "          66       1.00      0.11      0.20        18\n",
      "          67       1.00      0.50      0.67         2\n",
      "          68       0.00      0.00      0.00        24\n",
      "          69       0.75      0.25      0.38        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.83      0.73      0.78        89\n",
      "          72       1.00      0.12      0.22         8\n",
      "          73       0.60      0.30      0.40        10\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       1.00      0.09      0.17        11\n",
      "          76       0.85      0.52      0.64        33\n",
      "          77       1.00      0.09      0.17        11\n",
      "          78       0.93      0.69      0.79        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.50      0.20      0.29         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       1.00      0.08      0.15        12\n",
      "          84       0.51      0.68      0.58       117\n",
      "          85       0.70      0.43      0.53        37\n",
      "          86       0.62      0.83      0.71        71\n",
      "          87       1.00      0.10      0.18        10\n",
      "          88       0.25      0.14      0.18        14\n",
      "          89       1.00      0.08      0.14        13\n",
      "\n",
      "   micro avg       0.83      0.73      0.78      3744\n",
      "   macro avg       0.49      0.26      0.31      3744\n",
      "weighted avg       0.82      0.73      0.75      3744\n",
      " samples avg       0.77      0.78      0.76      3744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(new_y_test, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d9251c9defc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Confusion Matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m     71\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    258\u001b[0m         if (not hasattr(y[0], '__array__') and isinstance(y[0], Sequence)\n\u001b[0;32m    259\u001b[0m                 and not isinstance(y[0], str)):\n\u001b[1;32m--> 260\u001b[1;33m             raise ValueError('You appear to be using a legacy multi-label data'\n\u001b[0m\u001b[0;32m    261\u001b[0m                              \u001b[1;34m' representation. Sequence of sequences are no'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                              \u001b[1;34m' longer supported; use a binary array or sparse'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,14))\n",
    "sns.set()\n",
    "sns.heatmap(metrics.confusion_matrix(new_y_test, test_predict) , annot=True, fmt=\"d\", linewidths=.5)\n",
    "plt.title(\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
